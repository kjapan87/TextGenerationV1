{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Text Generation Try 2020-10-10.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kjapan87/TextGenerationV1/blob/main/Text_Generation_Try_2020_10_10.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cw_fXU1d8YQf"
      },
      "source": [
        "#STEP-1:::Create a function to Read training text file\n",
        "def read_file(filepath):\n",
        "    with open(filepath) as f:\n",
        "        str_text = f.read()\n",
        "    return str_text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UJPxJAdr8bUI"
      },
      "source": [
        "\n",
        "#STEP-2::: Reading the actual text\n",
        "training_text_data = read_file('moby_dick_four_chapters.txt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u1lj9NxP8iq3",
        "outputId": "cf14a075-1d79-4dfd-d678-5265784bb310",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "                 ###TOKENIZE & CLEAN TEXT###\n",
        "import spacy\n",
        "nlp = spacy.blank(\"en\")\n",
        "\n",
        "\n",
        "def Pre_Process(doc_text): #defining a function to pre-procecss training_text_data, by removing the punctuations and converting upper case to lower case\n",
        "    return [token.text.lower() for token in nlp(doc_text) if token.text not in '\\n\\n \\n\\n\\n!\"-#$%&()--.*+,-/:;<=>?@[\\\\]^_`{|}~\\t\\n ']\n",
        "\n",
        "\n",
        "spacy_tokens = Pre_Process(training_text_data)\n",
        "len(spacy_tokens)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "11338"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1SrtvWsU8kd2",
        "outputId": "1a3dc6fe-f0bf-4524-faeb-534f423d8459",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "train_len = 25+1 #defining and organizing the tokens into sliding window sequence,25 training words then 1 predicted word\n",
        "\n",
        "text_sequence = [] #declare an empty list\n",
        "for i in range(train_len,len(spacy_tokens)):\n",
        "    seq = spacy_tokens[i-train_len:i]  # Defining sliding windows of 25 words\n",
        "  \n",
        "    text_sequence.append(seq)          # Actually creating sliding windows of 25 words\n",
        "    \n",
        "' '.join(text_sequence[0])#no use, just for checking for-loop is working or not\n",
        "' '.join(text_sequence[1])#no use, just for checking for-loop is working or not\n",
        "' '.join(text_sequence[2])#no use, just for checking for-loop is working or not\n",
        "' '.join(text_sequence[3])#no use, just for checking for-loop is working or not\n",
        "\n",
        "len(text_sequence)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "11312"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "woGDQGck9FDq",
        "outputId": "a7576516-e577-487a-a404-f3d138e2c7f7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 479
        }
      },
      "source": [
        "                   ###KERAS TOKENIZATION###\n",
        "from keras.preprocessing.text import text_to_word_sequence,Tokenizer\n",
        "obj4 = Tokenizer()\n",
        "obj4.fit_on_texts(text_sequence)\n",
        "keras_tokens = obj4.texts_to_sequences(text_sequence) # converts a text file, into tokens & also removes basic punctuations tabs etc.(same as ln23 function)\n",
        "keras_tokens[0]\n",
        "\n",
        "\n",
        "for i in keras_tokens[0]:\n",
        "    print(f'{i} : {obj4.index_word[i]}')\n",
        "    \n",
        "vocab_size = len(obj4.word_counts)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "956 : call\n",
            "14 : me\n",
            "263 : ishmael\n",
            "51 : some\n",
            "261 : years\n",
            "408 : ago\n",
            "87 : never\n",
            "219 : mind\n",
            "129 : how\n",
            "111 : long\n",
            "954 : precisely\n",
            "260 : having\n",
            "50 : little\n",
            "43 : or\n",
            "38 : no\n",
            "315 : money\n",
            "7 : in\n",
            "23 : my\n",
            "546 : purse\n",
            "3 : and\n",
            "150 : nothing\n",
            "259 : particular\n",
            "6 : to\n",
            "2712 : interest\n",
            "14 : me\n",
            "24 : on\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TJIFPrt6B2ou",
        "outputId": "a6ea3167-067c-4f4d-b1a0-d162133bd322",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "vocab_size"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2717"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FrD2Pxjz9K0D"
      },
      "source": [
        "       ###CONVERT KERAS_TOKENS LIST TO NUMPY MATRIX###\n",
        "import numpy as np\n",
        "keras_tokens = np.array(keras_tokens) # convert keras_token(list) to keras_token(numpy arrays)\n",
        "#np.array or .str converts to any data type\n",
        "\n",
        "            ###ENCODE KERAS_TOKEN NUMPY WORD MATRIX AS INTEGER MATRIX###\n",
        "#from keras.preprocessing.text import one_hot\n",
        "#vocab_size = len(keras_tokens.word_counts)\n",
        "#encoded_keras_tokens = one_hot(training_text_data, vocab_size,filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n', lower=True,split=' ')       \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kUT2wp5V9PqP"
      },
      "source": [
        "       ###CONVERT KERAS_TOKEN NUMPY INTEGER MATRIX TO BINARY MATRIX###\n",
        "from numpy import array\n",
        "from numpy import argmax\n",
        "from keras.utils import to_categorical\n",
        "#encoded_keras_tokens_binary = to_categorical(encoded_keras_tokens)\n",
        "#inverted_encoded_keras_tokens_binary = argmax(encoded_keras_tokens_binary[0]) #invert encoding"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J8wHx7oT9X2H"
      },
      "source": [
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense,LSTM,Embedding\n",
        "\n",
        "def create_model(vocab_size, sequence_length):\n",
        "    model = Sequential()\n",
        "    model.add(Embedding(vocab_size,sequence_length, input_length=sequence_length))\n",
        "    model.add(LSTM(64, return_sequences=True))\n",
        "    model.add(LSTM(64))\n",
        "    model.add(Dense(64, activation='relu'))\n",
        "\n",
        "    model.add(Dense(vocab_size, activation='softmax'))\n",
        "    \n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "   \n",
        "    model.summary()\n",
        "    \n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GguzP8ROIOL_"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lx2I4oqh9Zi9"
      },
      "source": [
        "from keras.utils import to_categorical\n",
        "                \n",
        "x = keras_tokens[0:11313,0:25]\n",
        "y = keras_tokens[:,-1]\n",
        "y = to_categorical(y)\n",
        "\n",
        "sequence_length = x.shape[1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BL4Ulz_y-mQF",
        "outputId": "e3964843-4305-4e2c-f838-9a5572310ba6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "sequence_length"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "25"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5hElSdxZ-qMp",
        "outputId": "4df2b2b6-2542-437b-8061-522c9bd37a26",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "vocab_size"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2717"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dS00IXUW9ius",
        "outputId": "00a187ae-e47b-4f9c-d9d3-bf6258789fab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 337
        }
      },
      "source": [
        "model = create_model(vocab_size, sequence_length)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_13\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_11 (Embedding)     (None, 25, 25)            67925     \n",
            "_________________________________________________________________\n",
            "lstm_30 (LSTM)               (None, 25, 64)            23040     \n",
            "_________________________________________________________________\n",
            "lstm_31 (LSTM)               (None, 64)                33024     \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 64)                4160      \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 2717)              176605    \n",
            "=================================================================\n",
            "Total params: 304,754\n",
            "Trainable params: 304,754\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LPszfqK9BZAy",
        "outputId": "9d124d03-6fb0-4856-89cc-4ae96e6af376",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "vocab_size"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2717"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    }
  ]
}